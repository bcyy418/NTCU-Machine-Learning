{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import kagglehub\n",
        "\n",
        "RANDOM_STATE_VAL = 42\n",
        "TEST_SET_RATIO = 0.3\n",
        "\n",
        "print(\"Ê≠£Âú®ËºâÂÖ•Êï∏ÊìöÈõÜ...\")\n",
        "path_source = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "credit_data = pd.read_csv(f\"{path_source}/creditcard.csv\")\n",
        "credit_data['Class'] = credit_data['Class'].astype(int)\n",
        "credit_data.drop('Time', axis=1, inplace=True)\n",
        "\n",
        "amount_scaler = StandardScaler()\n",
        "credit_data['Amount'] = amount_scaler.fit_transform(credit_data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "num_fraud = credit_data[credit_data['Class'] == 1].shape[0]\n",
        "num_nonfraud = credit_data[credit_data['Class'] == 0].shape[0]\n",
        "print(f'Ë©êÊ¨∫‰∫§ÊòìÊï∏Èáè: {num_fraud}, Ê≠£Â∏∏‰∫§ÊòìÊï∏Èáè: {num_nonfraud}')\n",
        "print(f'Ê≠£Ê®£Êú¨ (Ë©êÊ¨∫) ÁôæÂàÜÊØî: {num_fraud / (num_fraud + num_nonfraud) * 100:.3f}%')\n",
        "\n",
        "features_X = credit_data.drop(columns=['Class']).values\n",
        "labels_y = credit_data['Class'].values\n",
        "\n",
        "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(\n",
        "    features_X, labels_y, test_size=TEST_SET_RATIO, random_state=RANDOM_STATE_VAL, stratify=labels_y\n",
        ")\n",
        "\n",
        "data_scaler = StandardScaler()\n",
        "X_train_scaled = data_scaler.fit_transform(X_train_set)\n",
        "X_test_scaled = data_scaler.transform(X_test_set)\n",
        "\n",
        "count_class_0 = np.sum(y_train_set == 0)\n",
        "count_class_1 = np.sum(y_train_set == 1)\n",
        "dynamic_scale_pos_weight = count_class_0 / count_class_1 if count_class_1 > 0 else 1\n",
        "print(f\"ÂãïÊÖãË®àÁÆóÁöÑ scale_pos_weight: {dynamic_scale_pos_weight:.2f}\")\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=2.5,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=RANDOM_SEED,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "print(\"ÈñãÂßãË®ìÁ∑¥ XGBoost Ê®°Âûã...\")\n",
        "xgb_classifier.fit(X_train_scaled, y_train_set)\n",
        "\n",
        "y_pred_probabilities = xgb_classifier.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_test_set, y_pred_probabilities)\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresh[optimal_idx]\n",
        "\n",
        "print(f\"\\nüîç Âü∫Êñº F1 ÂàÜÊï∏Ë®àÁÆóÂá∫ÁöÑÊúÄ‰Ω≥ÈñæÂÄº: {optimal_threshold:.4f}, Â∞çÊáâÁöÑ F1 ÂàÜÊï∏ = {f1_scores[optimal_idx]:.4f}\")\n",
        "\n",
        "y_final_predictions = (y_pred_probabilities > optimal_threshold).astype(int)\n",
        "\n",
        "print(\"\\n‰ΩøÁî®ÊúÄ‰Ω≥ÈñæÂÄºÁöÑ XGBoost ÂàÜÈ°ûÂ†±Âëä:\")\n",
        "print(classification_report(y_test_set, y_final_predictions, target_names=['Ê≠£Â∏∏‰∫§Êòì', 'Ë©êÊ¨∫‰∫§Êòì']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF8ImNFu3A5j",
        "outputId": "411fe3e3-8ff4-4b9d-e679-1ea265581214"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ê≠£Âú®ËºâÂÖ•Êï∏ÊìöÈõÜ...\n",
            "Ë©êÊ¨∫‰∫§ÊòìÊï∏Èáè: 492, Ê≠£Â∏∏‰∫§ÊòìÊï∏Èáè: 284315\n",
            "Ê≠£Ê®£Êú¨ (Ë©êÊ¨∫) ÁôæÂàÜÊØî: 0.173%\n",
            "ÂãïÊÖãË®àÁÆóÁöÑ scale_pos_weight: 578.55\n",
            "ÈñãÂßãË®ìÁ∑¥ XGBoost Ê®°Âûã...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:04:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Âü∫Êñº F1 ÂàÜÊï∏Ë®àÁÆóÂá∫ÁöÑÊúÄ‰Ω≥ÈñæÂÄº: 0.9282, Â∞çÊáâÁöÑ F1 ÂàÜÊï∏ = 0.8453\n",
            "\n",
            "‰ΩøÁî®ÊúÄ‰Ω≥ÈñæÂÄºÁöÑ XGBoost ÂàÜÈ°ûÂ†±Âëä:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Ê≠£Â∏∏‰∫§Êòì       1.00      1.00      1.00     85295\n",
            "        Ë©êÊ¨∫‰∫§Êòì       0.96      0.75      0.84       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.98      0.87      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import kagglehub\n",
        "\n",
        "# ‰∏ÄËà¨ÂèÉÊï∏\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "# ËºâÂÖ•Ë≥áÊñôÈõÜ\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "data['Class'] = data['Class'].astype(int)\n",
        "data.drop('Time', axis=1, inplace=True)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "# È°ØÁ§∫È°ûÂà•ÊØî‰æã\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "print(f'Fraudulent:{len(fraud)}, non-fraudulent:{len(nonfraud)}')\n",
        "print(f'the positive class (frauds) percentage: {len(fraud)/(len(fraud)+len(nonfraud))*100:.3f}%')\n",
        "\n",
        "# ÁâπÂæµËàáÊ®ôÁ±§\n",
        "X = data.drop(columns=['Class']).to_numpy()\n",
        "Y = data['Class'].to_numpy()\n",
        "\n",
        "# ÂàáÂàÜË®ìÁ∑¥ËàáÊ∏¨Ë©¶ÈõÜ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "# Ê®ôÊ∫ñÂåñ\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Âª∫Á´ã XGBoost Ê®°Âûã\n",
        "xgb_model = XGBClassifier(\n",
        "    colsample_bytree=0.95,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    n_estimators=250,\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=2.5,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist',\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Ë®ìÁ∑¥Ê®°Âûã\n",
        "xgb_model.fit(X_train_std, y_train)\n",
        "\n",
        "# Ê®°ÂûãÊ©üÁéáÈ†êÊ∏¨\n",
        "y_prob = xgb_model.predict_proba(X_test_std)[:, 1]\n",
        "\n",
        "threshold = 0.4031\n",
        "y_pred_custom = (y_prob > threshold).astype(int)\n",
        "\n",
        "# ÂàÜÈ°ûÂ†±Âëä\n",
        "print(classification_report(y_test, y_pred_custom))\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "best_idx = f1.argmax()\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(f\"\\nüîç Best Threshold based on F1: {best_threshold:.4f}, F1 = {f1[best_idx]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jYg5IeK5MUB",
        "outputId": "f5e58633-318b-4a3c-d306-95eb2ef795d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraudulent:492, non-fraudulent:284315\n",
            "the positive class (frauds) percentage: 0.173%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85307\n",
            "           1       0.91      0.86      0.88       136\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.95      0.93      0.94     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "\n",
            "üîç Best Threshold based on F1: 0.6064, F1 = 0.9070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import kagglehub\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "\n",
        "data['Class'] = data['Class'].astype(int)\n",
        "data.drop('Time', axis=1, inplace=True)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "\n",
        "# ‰øÆÊîπËº∏Âá∫ÊñáÂ≠ó\n",
        "print(f'Ë©êÈ®ôÊ°à‰æãÁ≠ÜÊï∏: {len(fraud)}, Ê≠£Â∏∏Ê°à‰æãÁ≠ÜÊï∏: {len(nonfraud)}')\n",
        "print(f'Ë©êÈ®ôÊ°à‰æãÂç†ÊØî (%): {len(fraud)/(len(fraud)+len(nonfraud))*100:.3f}')\n",
        "\n",
        "X = data.drop(columns=['Class']).to_numpy()\n",
        "Y = data['Class'].to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# XGBoost Ê®°ÂûãÂèÉÊï∏\n",
        "xgb_model = XGBClassifier(\n",
        "    colsample_bytree=1.0,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    n_estimators=100,\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=2.5,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist',\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_std, y_train)\n",
        "\n",
        "y_prob = xgb_model.predict_proba(X_test_std)[:, 1]\n",
        "\n",
        "threshold = 0.4031\n",
        "y_pred_custom = (y_prob > threshold).astype(int)\n",
        "\n",
        "\n",
        "print(\"\\n--- Ê®°ÂûãÂàÜÈ°ûÊàêÊïàÂ†±Âëä (Âõ∫ÂÆöÈñæÂÄº) ---\")\n",
        "print(classification_report(y_test, y_pred_custom, target_names=['Â∏∏Ë¶è‰∫§Êòì (Class 0)', 'ÂèØÁñë‰∫§Êòì (Class 1)']))\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "best_idx = f1.argmax()\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RatBLpk7QMe",
        "outputId": "e4e3f260-2221-4058-e351-ab64c208ff78"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ë©êÈ®ôÊ°à‰æãÁ≠ÜÊï∏: 492, Ê≠£Â∏∏Ê°à‰æãÁ≠ÜÊï∏: 284315\n",
            "Ë©êÈ®ôÊ°à‰æãÂç†ÊØî (%): 0.173\n",
            "\n",
            "--- Ê®°ÂûãÂàÜÈ°ûÊàêÊïàÂ†±Âëä (Âõ∫ÂÆöÈñæÂÄº) ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Â∏∏Ë¶è‰∫§Êòì (Class 0)       1.00      1.00      1.00     85307\n",
            "ÂèØÁñë‰∫§Êòì (Class 1)       0.94      0.86      0.90       136\n",
            "\n",
            "      accuracy                           1.00     85443\n",
            "     macro avg       0.97      0.93      0.95     85443\n",
            "  weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    }
  ]
}