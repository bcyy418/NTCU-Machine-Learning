{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import kagglehub\n",
        "\n",
        "RANDOM_STATE_VAL = 42\n",
        "TEST_SET_RATIO = 0.3\n",
        "\n",
        "print(\"æ­£åœ¨è¼‰å…¥æ•¸æ“šé›†...\")\n",
        "path_source = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "credit_data = pd.read_csv(f\"{path_source}/creditcard.csv\")\n",
        "credit_data['Class'] = credit_data['Class'].astype(int)\n",
        "credit_data.drop('Time', axis=1, inplace=True)\n",
        "\n",
        "amount_scaler = StandardScaler()\n",
        "credit_data['Amount'] = amount_scaler.fit_transform(credit_data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "num_fraud = credit_data[credit_data['Class'] == 1].shape[0]\n",
        "num_nonfraud = credit_data[credit_data['Class'] == 0].shape[0]\n",
        "print(f'è©æ¬ºäº¤æ˜“æ•¸é‡: {num_fraud}, æ­£å¸¸äº¤æ˜“æ•¸é‡: {num_nonfraud}')\n",
        "print(f'æ­£æ¨£æœ¬ (è©æ¬º) ç™¾åˆ†æ¯”: {num_fraud / (num_fraud + num_nonfraud) * 100:.3f}%')\n",
        "\n",
        "features_X = credit_data.drop(columns=['Class']).values\n",
        "labels_y = credit_data['Class'].values\n",
        "\n",
        "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(\n",
        "    features_X, labels_y, test_size=TEST_SET_RATIO, random_state=RANDOM_STATE_VAL, stratify=labels_y\n",
        ")\n",
        "\n",
        "data_scaler = StandardScaler()\n",
        "X_train_scaled = data_scaler.fit_transform(X_train_set)\n",
        "X_test_scaled = data_scaler.transform(X_test_set)\n",
        "\n",
        "count_class_0 = np.sum(y_train_set == 0)\n",
        "count_class_1 = np.sum(y_train_set == 1)\n",
        "dynamic_scale_pos_weight = count_class_0 / count_class_1 if count_class_1 > 0 else 1\n",
        "print(f\"å‹•æ…‹è¨ˆç®—çš„ scale_pos_weight: {dynamic_scale_pos_weight:.2f}\")\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=2.5,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=RANDOM_SEED,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "print(\"é–‹å§‹è¨“ç·´ XGBoost æ¨¡å‹...\")\n",
        "xgb_classifier.fit(X_train_scaled, y_train_set)\n",
        "\n",
        "y_pred_probabilities = xgb_classifier.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_test_set, y_pred_probabilities)\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresh[optimal_idx]\n",
        "\n",
        "print(f\"\\nğŸ” åŸºæ–¼ F1 åˆ†æ•¸è¨ˆç®—å‡ºçš„æœ€ä½³é–¾å€¼: {optimal_threshold:.4f}, å°æ‡‰çš„ F1 åˆ†æ•¸ = {f1_scores[optimal_idx]:.4f}\")\n",
        "\n",
        "y_final_predictions = (y_pred_probabilities > optimal_threshold).astype(int)\n",
        "\n",
        "print(\"\\nä½¿ç”¨æœ€ä½³é–¾å€¼çš„ XGBoost åˆ†é¡å ±å‘Š:\")\n",
        "print(classification_report(y_test_set, y_final_predictions, target_names=['æ­£å¸¸äº¤æ˜“', 'è©æ¬ºäº¤æ˜“']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF8ImNFu3A5j",
        "outputId": "411fe3e3-8ff4-4b9d-e679-1ea265581214"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨è¼‰å…¥æ•¸æ“šé›†...\n",
            "è©æ¬ºäº¤æ˜“æ•¸é‡: 492, æ­£å¸¸äº¤æ˜“æ•¸é‡: 284315\n",
            "æ­£æ¨£æœ¬ (è©æ¬º) ç™¾åˆ†æ¯”: 0.173%\n",
            "å‹•æ…‹è¨ˆç®—çš„ scale_pos_weight: 578.55\n",
            "é–‹å§‹è¨“ç·´ XGBoost æ¨¡å‹...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:04:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” åŸºæ–¼ F1 åˆ†æ•¸è¨ˆç®—å‡ºçš„æœ€ä½³é–¾å€¼: 0.9282, å°æ‡‰çš„ F1 åˆ†æ•¸ = 0.8453\n",
            "\n",
            "ä½¿ç”¨æœ€ä½³é–¾å€¼çš„ XGBoost åˆ†é¡å ±å‘Š:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        æ­£å¸¸äº¤æ˜“       1.00      1.00      1.00     85295\n",
            "        è©æ¬ºäº¤æ˜“       0.96      0.75      0.84       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.98      0.87      0.92     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import kagglehub\n",
        "\n",
        "# ä¸€èˆ¬åƒæ•¸\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "# è¼‰å…¥è³‡æ–™é›†\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "data['Class'] = data['Class'].astype(int)\n",
        "data.drop('Time', axis=1, inplace=True)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "# é¡¯ç¤ºé¡åˆ¥æ¯”ä¾‹\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "print(f'Fraudulent:{len(fraud)}, non-fraudulent:{len(nonfraud)}')\n",
        "print(f'the positive class (frauds) percentage: {len(fraud)/(len(fraud)+len(nonfraud))*100:.3f}%')\n",
        "\n",
        "# ç‰¹å¾µèˆ‡æ¨™ç±¤\n",
        "X = data.drop(columns=['Class']).to_numpy()\n",
        "Y = data['Class'].to_numpy()\n",
        "\n",
        "# åˆ‡åˆ†è¨“ç·´èˆ‡æ¸¬è©¦é›†\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "# æ¨™æº–åŒ–\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# å»ºç«‹ XGBoost æ¨¡å‹\n",
        "xgb_model = XGBClassifier(\n",
        "    colsample_bytree=0.95,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    n_estimators=250,\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=2.5,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist',\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# è¨“ç·´æ¨¡å‹\n",
        "xgb_model.fit(X_train_std, y_train)\n",
        "\n",
        "# æ¨¡å‹æ©Ÿç‡é æ¸¬\n",
        "y_prob = xgb_model.predict_proba(X_test_std)[:, 1]\n",
        "\n",
        "threshold = 0.4031\n",
        "y_pred_custom = (y_prob > threshold).astype(int)\n",
        "\n",
        "# åˆ†é¡å ±å‘Š\n",
        "print(classification_report(y_test, y_pred_custom))\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "best_idx = f1.argmax()\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(f\"\\nğŸ” Best Threshold based on F1: {best_threshold:.4f}, F1 = {f1[best_idx]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jYg5IeK5MUB",
        "outputId": "f5e58633-318b-4a3c-d306-95eb2ef795d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraudulent:492, non-fraudulent:284315\n",
            "the positive class (frauds) percentage: 0.173%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85307\n",
            "           1       0.91      0.86      0.88       136\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.95      0.93      0.94     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "\n",
            "ğŸ” Best Threshold based on F1: 0.6064, F1 = 0.9070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import kagglehub\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "\n",
        "data['Class'] = data['Class'].astype(int)\n",
        "data.drop('Time', axis=1, inplace=True)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "\n",
        "# ä¿®æ”¹è¼¸å‡ºæ–‡å­—\n",
        "print(f'è©é¨™æ¡ˆä¾‹ç­†æ•¸: {len(fraud)}, æ­£å¸¸æ¡ˆä¾‹ç­†æ•¸: {len(nonfraud)}')\n",
        "print(f'è©é¨™æ¡ˆä¾‹å æ¯” (%): {len(fraud)/(len(fraud)+len(nonfraud))*100:.3f}')\n",
        "\n",
        "X = data.drop(columns=['Class']).to_numpy()\n",
        "Y = data['Class'].to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# XGBoost æ¨¡å‹åƒæ•¸\n",
        "xgb_model = XGBClassifier(\n",
        "    colsample_bytree=1.0,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    n_estimators=100,\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=2.5,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist',\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_std, y_train)\n",
        "\n",
        "y_prob = xgb_model.predict_proba(X_test_std)[:, 1]\n",
        "\n",
        "threshold = 0.4031\n",
        "y_pred_custom = (y_prob > threshold).astype(int)\n",
        "\n",
        "\n",
        "print(\"\\n--- æ¨¡å‹åˆ†é¡æˆæ•ˆå ±å‘Š (å›ºå®šé–¾å€¼) ---\")\n",
        "print(classification_report(y_test, y_pred_custom, target_names=['å¸¸è¦äº¤æ˜“ (Class 0)', 'å¯ç–‘äº¤æ˜“ (Class 1)']))\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "best_idx = f1.argmax()\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RatBLpk7QMe",
        "outputId": "e4e3f260-2221-4058-e351-ab64c208ff78"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è©é¨™æ¡ˆä¾‹ç­†æ•¸: 492, æ­£å¸¸æ¡ˆä¾‹ç­†æ•¸: 284315\n",
            "è©é¨™æ¡ˆä¾‹å æ¯” (%): 0.173\n",
            "\n",
            "--- æ¨¡å‹åˆ†é¡æˆæ•ˆå ±å‘Š (å›ºå®šé–¾å€¼) ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "å¸¸è¦äº¤æ˜“ (Class 0)       1.00      1.00      1.00     85307\n",
            "å¯ç–‘äº¤æ˜“ (Class 1)       0.94      0.86      0.90       136\n",
            "\n",
            "      accuracy                           1.00     85443\n",
            "     macro avg       0.97      0.93      0.95     85443\n",
            "  weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    }
  ]
}