{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsVJ60B3IPlb",
        "outputId": "7e18d798-06ac-40bf-c598-e098b0c50c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "總詐騙交易筆數: 492，總正常交易筆數: 284315\n",
            "整體數據中詐騙交易百分比: 0.173%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:20:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   (Accuracy): 0.986044\n",
            "    (Precision): 0.969925\n",
            "    (Recall): 0.871622\n",
            "     (F1 Score): 0.918149\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "正常交易 (Class 0)       0.99      1.00      0.99      1500\n",
            "詐騙交易 (Class 1)       0.97      0.87      0.92       148\n",
            "\n",
            "      accuracy                           0.99      1648\n",
            "     macro avg       0.98      0.93      0.96      1648\n",
            "  weighted avg       0.99      0.99      0.99      1648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report\n",
        ")\n",
        "import kagglehub\n",
        "\n",
        "RANDOM_SEED_VALUE = 42\n",
        "TEST_DATA_RATIO = 0.3\n",
        "\n",
        "data_path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "raw_data = pd.read_csv(f\"{data_path}/creditcard.csv\")\n",
        "raw_data.drop(['Time'], axis=1, inplace=True)\n",
        "std_scaler = StandardScaler()\n",
        "raw_data['Amount'] = std_scaler.fit_transform(\n",
        "    raw_data['Amount'].values.reshape(-1, 1)\n",
        ")\n",
        "features_all = raw_data.drop(columns=['Class']).values\n",
        "labels_all = raw_data['Class'].values\n",
        "\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    features_all, labels_all,\n",
        "    test_size=TEST_DATA_RATIO,\n",
        "    random_state=RANDOM_SEED_VALUE,\n",
        "    stratify=labels_all\n",
        ")\n",
        "\n",
        "fraud_transactions = raw_data[raw_data['Class'] == 1]\n",
        "nonfraud_transactions = raw_data[raw_data['Class'] == 0]\n",
        "\n",
        "print(f'總詐騙交易筆數: {len(fraud_transactions)}，總正常交易筆數: {len(nonfraud_transactions)}')\n",
        "print(f'整體數據中詐騙交易百分比: {len(fraud_transactions)/(len(fraud_transactions)+len(nonfraud_transactions))*100:.3f}%')\n",
        "\n",
        "def assess_model_performance(true_labels, predicted_labels, model_name_tag=\"模型\"):\n",
        "    accuracy_val = accuracy_score(true_labels, predicted_labels)\n",
        "    precision_val = precision_score(true_labels, predicted_labels, zero_division=0)\n",
        "    recall_val = recall_score(true_labels, predicted_labels)\n",
        "    f1_val = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "\n",
        "    print(f'   (Accuracy): {accuracy_val:.6f}')\n",
        "    print(f'    (Precision): {precision_val:.6f}')\n",
        "    print(f'    (Recall): {recall_val:.6f}')\n",
        "    print(f'     (F1 Score): {f1_val:.6f}')\n",
        "\n",
        "    print(classification_report(true_labels, predicted_labels, target_names=['正常交易 (Class 0)', '詐騙交易 (Class 1)']))\n",
        "\n",
        "\n",
        "selected_feature_columns = ['V1','V2','V3','V4','V5','V6','V7',\n",
        "                           'V9','V10','V11','V12','V14','V16','V17','V18','V19','Amount']\n",
        "\n",
        "X_selected_from_data = raw_data[selected_feature_columns].to_numpy()\n",
        "y_labels_from_data = raw_data['Class'].to_numpy()\n",
        "\n",
        "nonfraud_samples_for_balance = nonfraud_transactions.sample(n=5000, random_state=RANDOM_SEED_VALUE)\n",
        "data_for_balancing = pd.concat([fraud_transactions, nonfraud_samples_for_balance])\n",
        "\n",
        "X_features_from_balanced = data_for_balancing[selected_feature_columns].to_numpy()\n",
        "y_labels_from_balanced = data_for_balancing['Class'].to_numpy()\n",
        "\n",
        "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(\n",
        "    X_features_from_balanced, y_labels_from_balanced,\n",
        "    test_size=TEST_DATA_RATIO,\n",
        "    random_state=RANDOM_SEED_VALUE,\n",
        "    stratify=y_labels_from_balanced\n",
        ")\n",
        "\n",
        "isolation_forest_model = IsolationForest(\n",
        "        n_estimators=400,\n",
        "        max_samples='auto',\n",
        "        contamination='auto',\n",
        "        bootstrap=True,\n",
        "        random_state=RANDOM_SEED_VALUE\n",
        "    )\n",
        "isolation_forest_model.fit(X_train_balanced[y_train_balanced == 0])\n",
        "\n",
        "anomaly_scores_train = (-isolation_forest_model.decision_function(X_train_balanced)).reshape(-1, 1)\n",
        "anomaly_scores_test  = (-isolation_forest_model.decision_function(X_test_balanced )).reshape(-1, 1)\n",
        "\n",
        "X_train_with_anomaly_score = np.hstack([X_train_balanced, anomaly_scores_train])\n",
        "X_test_with_anomaly_score  = np.hstack([X_test_balanced , anomaly_scores_test ])\n",
        "\n",
        "pos_weight_for_xgb = (y_train_balanced == 0).sum() / (y_train_balanced == 1).sum()\n",
        "\n",
        "xgb_hybrid_model = XGBClassifier(\n",
        "    n_estimators=350,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.08,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=pos_weight_for_xgb,\n",
        "    random_state=RANDOM_SEED_VALUE,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False # 避免 UserWarning\n",
        ")\n",
        "xgb_hybrid_model.fit(X_train_with_anomaly_score, y_train_balanced)\n",
        "\n",
        "y_predictions_hybrid = xgb_hybrid_model.predict(X_test_with_anomaly_score)\n",
        "\n",
        "assess_model_performance(y_test_balanced, y_predictions_hybrid, model_name_tag=\"混合模型 (Isolation Forest + XGBoost)\")"
      ]
    }
  ]
}