---
# 挑戰二：Hybrid Model
---



使用技術與核心思路

### 1. 特徵工程與篩選策略

在建構高效能的機器學習模型時，特徵的選擇與處理至關重要。並非使用數據集中的所有原始特徵，而是有策略地篩選和轉換，以提升模型的學習效率和預測準確性。

初步特徵集定義：基於對信用卡詐欺模式的理解以及初步的探索性數據分析(EDA)，我們識別出一組與詐欺行為具有較高相關性或區分度的特徵。這些特徵主要源自經過主成分分析 (PCA) 處理後的 `V` 系列匿名變數，以及經過標準化處理的 `Amount`（交易金額）欄位。選定的特徵集如下：
    ```python
    selected_features = ['V1','V2','V3','V4','V5','V6','V7',
                         'V9','V10','V11','V12','V14','V16','V17','V18','V19','Amount']
    ```


---

### 2.  數據集平衡化處理方案

信用卡詐欺數據本質上是高度不平衡的，正常交易遠多於詐欺交易。這種不平衡會嚴重影響模型的學習，使其傾向於預測多數類別。為此，我們採用了數據層面的平衡策略。

* **下採樣 (Undersampling) 技術應用**：我們主要對佔多數的正常交易樣本進行下採樣。具體做法是從所有正常樣本中隨機抽取一個固定數量（例如，本例中設定為 5000 筆）的子集。
* **構建平衡訓練集**：將下採樣得到的正常交易樣本與**所有**的詐欺交易樣本進行合併，形成一個新的、數據規模縮小且類別分佈相對均衡的數據集。這個平衡後的數據集將專門用於後續模型的訓練階段。
* **維持測試集原始分佈**：重要的是，測試集應保持其原始的、未經採樣的類別分佈，這樣才能真實地評估模型在實際場景中的泛化能力和對不平衡數據的處理效果。(*在本挑戰的特定流程中，如果後續的 `train_test_split` 是在已平衡的數據集上進行，則訓練集和測試集都會來自這個平衡後的數據，這點需根據實際流程確認。*)

---

### 3. Isolation Forest（非監督式異常分數生成）

在將數據餵給最終的監督式分類器之前，我們先利用 Isolation Forest 演算法來捕捉數據中的異常結構，並將其量化為一個新的特徵。

* **模型訓練的特定策略**：為了讓 Isolation Forest 更精準地學習「正常」數據的輪廓，我們**僅使用平衡訓練集中的正常樣本**（即 `y_train == 0` 的部分）來訓練 `IsolationForest` 模型。這樣做的目的是避免詐欺樣本的異常模式干擾模型對正常行為邊界的定義，從而更有效地識別出與已知正常模式不符的未知異常。
* **異常分數的計算與轉換**：
    * `IsolationForest` 的 `decision_function()` 方法會為每個樣本計算一個異常分數。原始分數通常是越低代表越異常（因為異常點更容易被「孤立」，在決策樹中的平均路徑更短）。
    * 為了使這個分數更直觀地表示「風險」（即分數越高，風險越大），我們對原始異常分數進行了**反向處理**（例如，取負值）。
* **異常分數作為新特徵**：將計算並轉換後的異常分數作為一個全新的特徵，拼接到原始的特徵矩陣中。這樣，每個樣本除了原有的 `selected_features` 外，還會額外擁有一個由 Isolation Forest 產生的「異常風險評分」。
    ```python
    # 計算訓練集和測試集的異常分數 (已反向)
    iso_train_scores = (-iso_model.decision_function(X_train_balanced_features)).reshape(-1, 1)
    iso_test_scores  = (-iso_model.decision_function(X_test_balanced_features)).reshape(-1, 1)

    # 將異常分數加入特徵集
    X_train_enhanced = np.hstack([X_train_balanced_features, iso_train_scores])
    X_test_enhanced  = np.hstack([X_test_balanced_features, iso_test_scores])
    ```
    這個新增的特徵為後續的 XGBoost 模型提供了來自非監督式角度的額外判斷依據，有助於提升整體檢測效能。

---
